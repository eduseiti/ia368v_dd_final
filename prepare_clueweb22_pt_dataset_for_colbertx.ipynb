{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "642a987d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e886f0fb"
      },
      "outputs": [],
      "source": [
        "IN_COLAB='google.colab' in sys.modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91c83783",
        "outputId": "6b0d3b7a-bfcd-4205-a137-3480077dfbc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "\n",
        "    WORKING_FOLDER=\"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR\"\n",
        "\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    os.chdir(WORKING_FOLDER)\n",
        "    \n",
        "    !pip install transformers -q\n",
        "    !pip install mlflow -q\n",
        "    !pip install ujson -q\n",
        "    !pip install faiss-gpu -q\n",
        "    !pip install SentencePiece -q    \n",
        "    \n",
        "    if not os.path.exists(\"ColBERT-X\"):\n",
        "        !git clone https://github.com/hltcoe/ColBERT-X.git\n",
        "            \n",
        "    PYTHON=\"python3\"\n",
        "else:\n",
        "    WORKING_FOLDER=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/trabalho_final/\"\n",
        "    \n",
        "    PỲTHON=\"python3.8\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLUEWEB22_FOLDER=\"clueweb22-pt\""
      ],
      "metadata": {
        "id": "WkhRgyKicBHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLUEWEB_COLBERT_CORPUS_FILENAME_FORMAT=\"clueweb22_pt_colbertx_{:02}.tsv\"\n",
        "CLUEWEB_COLBERT_TO_CLUEWEB_ID_FILENAME_FORMAT=\"clueweb22_pt_colbertx_to_clueweb_id_{:02}.tsv\"\n",
        "CLUEWEB_COLBERT_CORPUS_PASSAGE_FORMAT=\"{}\\t{}\""
      ],
      "metadata": {
        "id": "kSriqV8b9aNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import tqdm\n",
        "import re"
      ],
      "metadata": {
        "id": "YhqWEFjt88t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = glob.glob(os.path.join(CLUEWEB22_FOLDER, \"*.jsonl\"))\n",
        "\n",
        "print(corpus[0])"
      ],
      "metadata": {
        "id": "K2KnUclA9Bo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d233f55b-f93c-432c-f60f-47cfe30cfdf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clueweb22-pt/corpus_windowed_v2_pt0000.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert corpus to ColBERT-X format"
      ],
      "metadata": {
        "id": "2O6XS1sCIfeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colbertx_to_clueweb_id = []\n",
        "\n",
        "with open(corpus[0]) as input_file:\n",
        "    with open(os.path.join(CLUEWEB22_FOLDER, CLUEWEB_COLBERT_CORPUS_FILENAME_FORMAT.format(1)), \"w\") as output_file :\n",
        "        for i, line in enumerate(tqdm.tqdm(input_file)):\n",
        "            passage = json.loads(line)\n",
        "\n",
        "            if i > 0:\n",
        "                output_file.write(\"\\n\")\n",
        "\n",
        "            colbertx_to_clueweb_id.append(passage['id'])\n",
        "\n",
        "            output_file.write(CLUEWEB_COLBERT_CORPUS_PASSAGE_FORMAT.format(i, \n",
        "                                                                           re.sub('[\\r\\n\\t]', ' ', passage['contents'])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf7_ldL19Ibs",
        "outputId": "13f4230f-7686-4f90-a802-c002b6745677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22764703it [14:10, 26754.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(CLUEWEB22_FOLDER, CLUEWEB_COLBERT_TO_CLUEWEB_ID_FILENAME_FORMAT.format(1)), \"w\") as output_file:\n",
        "    for i, clueweb_id in enumerate(colbertx_to_clueweb_id):\n",
        "        if i > 0:\n",
        "            output_file.write(\"\\n\")\n",
        "\n",
        "        output_file.write(\"{}\\t{}\".format(i, clueweb_id))"
      ],
      "metadata": {
        "id": "LJoRCcTnAmMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate the index"
      ],
      "metadata": {
        "id": "gSxn9b1p_6BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"ColBERT-X\")"
      ],
      "metadata": {
        "id": "d1pF2hRTIkAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m xlmr_colbert.index --similarity l2 \\\n",
        "\t\t--checkpoint ../colbertx_experiments/mMSMARCO-pt/train.py/fine_tune_012/checkpoints/colbert-20000.dnn \\\n",
        "\t\t--index_root ../clueweb22-pt --index_name colbertx_index_pt0000 \\\n",
        "\t\t--collection ../clueweb22-pt/clueweb22_pt_colbertx_01.tsv --doc_maxlen 480 --query_maxlen 32 --dim 64 --amp --bsize=512 --chunksize=24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgQVf6ksJTau",
        "outputId": "7b538c66-e66c-4600-f700-02fc0f4c2ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-11 10:49:34.134039: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-06-11 10:49:34.187034: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-11 10:49:35.161400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "[Jun 11, 10:49:45] #> Creating directory /content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/experiments/dirty/index.py/2023-06-11_10.49.36 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[Jun 11, 10:49:51] #> Creating directory /content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/experiments/dirty/index.py/2023-06-11_10.49.36/logs/ \n",
            "\n",
            "\n",
            "[Jun 11, 10:49:52] {'root': 'experiments', 'experiment': 'dirty', 'run': '2023-06-11_10.49.36', 'rank': -1, 'similarity': 'l2', 'dim': 64, 'query_maxlen': 32, 'doc_maxlen': 480, 'mask_punctuation': False, 'checkpoint': '../colbertx_experiments/mMSMARCO-pt/train.py/fine_tune_012/checkpoints/colbert-20000.dnn', 'bsize': 512, 'amp': True, 'collection': '../clueweb22-pt/clueweb22_pt_colbertx_01.tsv', 'index_root': '../clueweb22-pt', 'index_name': 'colbertx_index_pt0000', 'chunksize': 24.0} \n",
            "\n",
            "\n",
            "\n",
            "[Jun 11, 10:49:52] #> Note: Output directory ../clueweb22-pt already exists\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[Jun 11, 10:49:52] #> Creating directory ../clueweb22-pt/colbertx_index_pt0000 \n",
            "\n",
            "\n",
            "[Jun 11, 10:49:52] [0] \t\t #> Local args.bsize = 512\n",
            "[Jun 11, 10:49:52] [0] \t\t #> args.index_root = ../clueweb22-pt\n",
            "[Jun 11, 10:49:52] [0] \t\t #> self.possible_subset_sizes = [419430]\n",
            "Downloading (…)lve/main/config.json: 100% 616/616 [00:00<00:00, 4.41MB/s]\n",
            "Downloading model.safetensors: 100% 2.24G/2.24G [00:05<00:00, 411MB/s]\n",
            "XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.30.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "Downloading (…)tencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 10.5MB/s]\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing ColBERT: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ColBERT were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['roberta.embeddings.position_ids', 'linear.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[Jun 11, 10:50:09] #> Loading model checkpoint.\n",
            "[Jun 11, 10:50:09] #> Loading checkpoint ../colbertx_experiments/mMSMARCO-pt/train.py/fine_tune_012/checkpoints/colbert-20000.dnn ..\n",
            "[Jun 11, 10:51:42] [WARNING] Loading checkpoint with strict=False\n",
            "[Jun 11, 10:51:44] Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/utils/utils.py\", line 74, in load_checkpoint\n",
            "    model.load_state_dict(checkpoint['model_state_dict'])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2041, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for ColBERT:\n",
            "\tsize mismatch for linear.weight: copying a param with shape torch.Size([128, 1024]) from checkpoint, the shape in current model is torch.Size([64, 1024]).\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/utils/runs.py\", line 70, in context\n",
            "    yield\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/index.py\", line 39, in main\n",
            "    encoder = CollectionEncoder(args, process_idx=process_idx, num_processes=args.nranks)\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/indexing/encoder.py\", line 40, in __init__\n",
            "    self._load_model()\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/indexing/encoder.py\", line 52, in _load_model\n",
            "    self.colbert, self.checkpoint = load_colbert(self.args, do_print=(self.process_idx == 0))\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/evaluation/loaders.py\", line 178, in load_colbert\n",
            "    colbert, checkpoint = load_model(args, do_print)\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/evaluation/load_model.py\", line 27, in load_model\n",
            "    checkpoint = load_checkpoint(args.checkpoint, colbert, do_print=do_print)\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/utils/utils.py\", line 77, in load_checkpoint\n",
            "    model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2041, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for ColBERT:\n",
            "\tsize mismatch for linear.weight: copying a param with shape torch.Size([128, 1024]) from checkpoint, the shape in current model is torch.Size([64, 1024]).\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/utils/utils.py\", line 74, in load_checkpoint\n",
            "    model.load_state_dict(checkpoint['model_state_dict'])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2041, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for ColBERT:\n",
            "\tsize mismatch for linear.weight: copying a param with shape torch.Size([128, 1024]) from checkpoint, the shape in current model is torch.Size([64, 1024]).\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/index.py\", line 57, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/index.py\", line 39, in main\n",
            "    encoder = CollectionEncoder(args, process_idx=process_idx, num_processes=args.nranks)\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/indexing/encoder.py\", line 40, in __init__\n",
            "    self._load_model()\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/indexing/encoder.py\", line 52, in _load_model\n",
            "    self.colbert, self.checkpoint = load_colbert(self.args, do_print=(self.process_idx == 0))\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/evaluation/loaders.py\", line 178, in load_colbert\n",
            "    colbert, checkpoint = load_model(args, do_print)\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/evaluation/load_model.py\", line 27, in load_model\n",
            "    checkpoint = load_checkpoint(args.checkpoint, colbert, do_print=do_print)\n",
            "  File \"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/xlmr_colbert/utils/utils.py\", line 77, in load_checkpoint\n",
            "    model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2041, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for ColBERT:\n",
            "\tsize mismatch for linear.weight: copying a param with shape torch.Size([128, 1024]) from checkpoint, the shape in current model is torch.Size([64, 1024]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu -q"
      ],
      "metadata": {
        "id": "ETa04Mu_J8_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m xlmr_colbert.index_faiss --index_root ../clueweb22-pt --index_name colbertx_index_pt0000"
      ],
      "metadata": {
        "id": "E7ofAVXvEQXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7dupPqgEQt0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}