{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP2X7YcTJUDcqXQbAe/ZZoN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduseiti/ia368v_dd_final/blob/master/create_clueweb22_pt_colbertx_index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "642a987d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e886f0fb"
      },
      "outputs": [],
      "source": [
        "IN_COLAB='google.colab' in sys.modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91c83783",
        "outputId": "a644a11d-560d-41b6-8323-6eb97b6ddb7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "\n",
        "    WORKING_FOLDER=\"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR\"\n",
        "\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    os.chdir(WORKING_FOLDER)\n",
        "\n",
        "    !pip install transformers -q\n",
        "    !pip install mlflow -q\n",
        "    !pip install ujson -q\n",
        "    !pip install faiss-gpu -q\n",
        "    !pip install SentencePiece -q\n",
        "\n",
        "    if not os.path.exists(\"ColBERT-X\"):\n",
        "        !git clone https://github.com/hltcoe/ColBERT-X.git\n",
        "\n",
        "    PYTHON=\"python3\"\n",
        "else:\n",
        "    WORKING_FOLDER=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/trabalho_final/\"\n",
        "\n",
        "    PỲTHON=\"python3.8\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(WORKING_FOLDER)"
      ],
      "metadata": {
        "id": "OGNcgEOOph6u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import tqdm\n",
        "import re\n",
        "import time\n",
        "import shutil"
      ],
      "metadata": {
        "id": "823ll0cem0jE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the corpus part index to create the index"
      ],
      "metadata": {
        "id": "ljz-MvlApR7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLBERT_CORPUS_PART_INDEX=0"
      ],
      "metadata": {
        "id": "0x0N5urGoL-n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define other constants"
      ],
      "metadata": {
        "id": "cAKnlDvtpVdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLBERTX_CORPUS_ORIGINAL_FOLDER=\"clueweb22-pt_10M_sample\"\n",
        "COLBERTX_CORPUS_VM_FOLDER=\"/content\"\n",
        "\n",
        "COLBERTX_INDEX_FOLDER=\"clueweb22-pt_10M_sample_part_{:02}_index\".format(COLBERT_CORPUS_PART_INDEX)\n",
        "\n",
        "COLBERT_CORPUS_PART_FILENAME=\"clueweb22-pt_colbertx_{:02}.tsv\".format(COLBERT_CORPUS_PART_INDEX)"
      ],
      "metadata": {
        "id": "WkhRgyKicBHx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy the corpus part file to the local VM to speedup the index creation process"
      ],
      "metadata": {
        "id": "iyO6VLFLnpZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "shutil.copy(os.path.join(COLBERTX_CORPUS_ORIGINAL_FOLDER, COLBERT_CORPUS_PART_FILENAME), COLBERTX_CORPUS_VM_FOLDER)\n",
        "\n",
        "print(\"Time to copy the corpus file: {}\".format(time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSKpJE0xnpfv",
        "outputId": "e8dcaa40-6878-4bcd-e582-17c9f2eb1403"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to copy the corpus file: 73.84907341003418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the colbertx index"
      ],
      "metadata": {
        "id": "AglkHo8WnplI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"ColBERT-X\")"
      ],
      "metadata": {
        "id": "JcB3LYrrqvUJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "!python3 -m xlmr_colbert.index --similarity l2 \\\n",
        "\t\t--checkpoint ../colbertx_experiments/mMSMARCO-pt_048_dim/train.py/fine_tune_025/checkpoints/colbert-20000.dnn \\\n",
        "\t\t--index_root ../{COLBERTX_CORPUS_ORIGINAL_FOLDER} --index_name {COLBERTX_INDEX_FOLDER} \\\n",
        "\t\t--collection {COLBERTX_CORPUS_VM_FOLDER}/{COLBERT_CORPUS_PART_FILENAME} --doc_maxlen 480 --query_maxlen 32 --dim 48 --amp --bsize=512 --chunksize=24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSLibzQznppY",
        "outputId": "ad912cbf-ba05-497f-c8d0-91a9ea3a200b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-18 18:09:44.418248: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-06-18 18:09:44.471767: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-18 18:09:45.441057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "[Jun 18, 18:10:03] #> Creating directory /content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/experiments/dirty/index.py/2023-06-18_18.09.47 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[Jun 18, 18:10:13] #> Creating directory /content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/experiments/dirty/index.py/2023-06-18_18.09.47/logs/ \n",
            "\n",
            "\n",
            "[Jun 18, 18:10:13] {'root': 'experiments', 'experiment': 'dirty', 'run': '2023-06-18_18.09.47', 'rank': -1, 'similarity': 'l2', 'dim': 48, 'query_maxlen': 32, 'doc_maxlen': 480, 'mask_punctuation': False, 'checkpoint': '../colbertx_experiments/mMSMARCO-pt_048_dim/train.py/fine_tune_025/checkpoints/colbert-20000.dnn', 'bsize': 512, 'amp': True, 'collection': '/content/clueweb22-pt_colbertx_00.tsv', 'index_root': '../clueweb22-pt_10M_sample', 'index_name': 'clueweb22-pt_10M_sample_part_00_index', 'chunksize': 24.0} \n",
            "\n",
            "\n",
            "\n",
            "[Jun 18, 18:10:13] #> Note: Output directory ../clueweb22-pt_10M_sample already exists\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[Jun 18, 18:10:13] #> Creating directory ../clueweb22-pt_10M_sample/clueweb22-pt_10M_sample_part_00_index \n",
            "\n",
            "\n",
            "[Jun 18, 18:10:13] [0] \t\t #> Local args.bsize = 512\n",
            "[Jun 18, 18:10:13] [0] \t\t #> args.index_root = ../clueweb22-pt_10M_sample\n",
            "[Jun 18, 18:10:13] [0] \t\t #> self.possible_subset_sizes = [559240]\n",
            "Downloading (…)lve/main/config.json: 100% 616/616 [00:00<00:00, 3.54MB/s]\n",
            "Downloading model.safetensors: 100% 2.24G/2.24G [00:04<00:00, 534MB/s]\n",
            "XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.30.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "Downloading (…)tencepiece.bpe.model: 100% 5.07M/5.07M [00:01<00:00, 3.42MB/s]\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing ColBERT: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ColBERT were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['roberta.embeddings.position_ids', 'linear.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[Jun 18, 18:10:31] #> Loading model checkpoint.\n",
            "[Jun 18, 18:10:31] #> Loading checkpoint ../colbertx_experiments/mMSMARCO-pt_048_dim/train.py/fine_tune_025/checkpoints/colbert-20000.dnn ..\n",
            "[Jun 18, 18:12:33] #> checkpoint['epoch'] = 0\n",
            "[Jun 18, 18:12:33] #> checkpoint['batch'] = 20000\n",
            "{\n",
            "    \"root\": \"..\\/colbertx_experiments\\/\",\n",
            "    \"experiment\": \"mMSMARCO-pt_048_dim\",\n",
            "    \"run\": \"fine_tune_025\",\n",
            "    \"rank\": -1,\n",
            "    \"similarity\": \"l2\",\n",
            "    \"dim\": 48,\n",
            "    \"query_maxlen\": 32,\n",
            "    \"doc_maxlen\": 480,\n",
            "    \"mask_punctuation\": false,\n",
            "    \"resume\": false,\n",
            "    \"resume_optimizer\": false,\n",
            "    \"checkpoint\": \"..\\/colbertx_experiments\\/mMSMARCO-pt_048_dim\\/train.py\\/fine_tune_012\\/checkpoints\\/colbert-20000.dnn\",\n",
            "    \"lr\": 3e-6,\n",
            "    \"maxsteps\": 20000,\n",
            "    \"bsize\": 12,\n",
            "    \"accumsteps\": 1,\n",
            "    \"amp\": true,\n",
            "    \"base_model\": \"xlm-roberta-large\",\n",
            "    \"triples\": \"..\\/mMARCO_triplets_025.tsv\",\n",
            "    \"queries\": null,\n",
            "    \"collection\": null\n",
            "}\n",
            "\n",
            "\n",
            "[Jun 18, 19:10:16] [0] \t\t #> Completed batch #0 (starting at passage #0) \t\tPassages/min: 9.7k (overall),  9.7k (this encoding),  760742.5M (this saving)\n",
            "[Jun 18, 19:11:25] [0] \t\t #> Saved batch #0 to ../clueweb22-pt_10M_sample/clueweb22-pt_10M_sample_part_00_index/0.pt \t\t Saving Throughput = 490.8k passages per minute.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total time to create the ColBERT-X index: {}\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "ZwhEfp7arazh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now, generate the FAISS index"
      ],
      "metadata": {
        "id": "ef55epFHnpta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "OgH3ddbgrgRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m xlmr_colbert.index_faiss --index_root ../{COLBERTX_CORPUS_ORIGINAL_FOLDER} --index_name {COLBERTX_INDEX_FOLDER}"
      ],
      "metadata": {
        "id": "9JZXsWqznpxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total time to create the FAISS index: {}\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "-A7QIHxBnp03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jiWrdLlOnqPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}