{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNVviPtyyz+Lhtn7n3BlC72",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduseiti/ia368v_dd_final/blob/master/create_clueweb22_pt_colbertx_index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "642a987d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e886f0fb"
      },
      "outputs": [],
      "source": [
        "IN_COLAB='google.colab' in sys.modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91c83783",
        "outputId": "e89580cb-2558-4fe5-eb40-b16a58abed45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "\n",
        "    WORKING_FOLDER=\"/content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR\"\n",
        "\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    os.chdir(WORKING_FOLDER)\n",
        "\n",
        "    !pip install transformers -q\n",
        "    !pip install mlflow -q\n",
        "    !pip install ujson -q\n",
        "    !pip install faiss-gpu -q\n",
        "    !pip install SentencePiece -q\n",
        "\n",
        "    if not os.path.exists(\"ColBERT-X\"):\n",
        "        !git clone https://github.com/hltcoe/ColBERT-X.git\n",
        "\n",
        "    PYTHON=\"python3\"\n",
        "else:\n",
        "    WORKING_FOLDER=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/trabalho_final/\"\n",
        "\n",
        "    PỲTHON=\"python3.8\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(WORKING_FOLDER)"
      ],
      "metadata": {
        "id": "OGNcgEOOph6u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import tqdm\n",
        "import re\n",
        "import time\n",
        "import shutil"
      ],
      "metadata": {
        "id": "823ll0cem0jE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the corpus part index to create the index"
      ],
      "metadata": {
        "id": "ljz-MvlApR7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLBERT_CORPUS_PART_INDEX=0"
      ],
      "metadata": {
        "id": "0x0N5urGoL-n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define other constants"
      ],
      "metadata": {
        "id": "cAKnlDvtpVdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLBERTX_CORPUS_ORIGINAL_FOLDER=\"clueweb22-pt_10M_sample\"\n",
        "COLBERTX_CORPUS_VM_FOLDER=\"/content\"\n",
        "\n",
        "COLBERTX_INDEX_FOLDER=\"clueweb22-pt_10M_sample_part_{:02}_index\".format(COLBERT_CORPUS_PART_INDEX)\n",
        "\n",
        "COLBERT_CORPUS_PART_FILENAME=\"clueweb22-pt_colbertx_{:02}.tsv\".format(COLBERT_CORPUS_PART_INDEX)"
      ],
      "metadata": {
        "id": "WkhRgyKicBHx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy the corpus part file to the local VM to speedup the index creation process"
      ],
      "metadata": {
        "id": "iyO6VLFLnpZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "shutil.copy(os.path.join(COLBERTX_CORPUS_ORIGINAL_FOLDER, COLBERT_CORPUS_PART_FILENAME), COLBERTX_CORPUS_VM_FOLDER)\n",
        "\n",
        "print(\"Time to copy the corpus file: {}\".format(time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSKpJE0xnpfv",
        "outputId": "dbe3a3a4-acaf-4217-f99d-c8acf27c5067"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to copy the corpus file: 19.161085605621338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the colbertx index"
      ],
      "metadata": {
        "id": "AglkHo8WnplI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"ColBERT-X\")"
      ],
      "metadata": {
        "id": "JcB3LYrrqvUJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "!python3 -m xlmr_colbert.index --similarity l2 \\\n",
        "\t\t--checkpoint ../colbertx_experiments/mMSMARCO-pt_048_dim/train.py/fine_tune_025/checkpoints/colbert-20000.dnn \\\n",
        "\t\t--index_root /content --index_name {COLBERTX_INDEX_FOLDER} \\\n",
        "\t\t--collection {COLBERTX_CORPUS_VM_FOLDER}/{COLBERT_CORPUS_PART_FILENAME} --doc_maxlen 480 --query_maxlen 32 --dim 48 --amp --bsize=576 --chunksize=9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSLibzQznppY",
        "outputId": "d51d6c09-2fd2-46d4-e7cc-b7248e0ded58"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-19 18:07:11.930850: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-06-19 18:07:11.985222: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-19 18:07:13.026204: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "[Jun 19, 18:07:24] #> Creating directory /content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/experiments/dirty/index.py/2023-06-19_18.07.14 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[Jun 19, 18:07:32] #> Creating directory /content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/experiments/dirty/index.py/2023-06-19_18.07.14/logs/ \n",
            "\n",
            "\n",
            "[Jun 19, 18:07:32] {'root': 'experiments', 'experiment': 'dirty', 'run': '2023-06-19_18.07.14', 'rank': -1, 'similarity': 'l2', 'dim': 48, 'query_maxlen': 32, 'doc_maxlen': 480, 'mask_punctuation': False, 'checkpoint': '../colbertx_experiments/mMSMARCO-pt_048_dim/train.py/fine_tune_025/checkpoints/colbert-20000.dnn', 'bsize': 576, 'amp': True, 'collection': '/content/clueweb22-pt_colbertx_00.tsv', 'index_root': '/content', 'index_name': 'clueweb22-pt_10M_sample_part_00_index', 'chunksize': 9.0} \n",
            "\n",
            "\n",
            "\n",
            "[Jun 19, 18:07:32] #> Note: Output directory /content already exists\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[Jun 19, 18:07:32] #> Creating directory /content/clueweb22-pt_10M_sample_part_00_index \n",
            "\n",
            "\n",
            "[Jun 19, 18:07:32] [0] \t\t #> Local args.bsize = 576\n",
            "[Jun 19, 18:07:32] [0] \t\t #> args.index_root = /content\n",
            "[Jun 19, 18:07:32] [0] \t\t #> self.possible_subset_sizes = [209715]\n",
            "Downloading (…)lve/main/config.json: 100% 616/616 [00:00<00:00, 4.25MB/s]\n",
            "Downloading model.safetensors: 100% 2.24G/2.24G [00:09<00:00, 241MB/s]\n",
            "XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.30.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "Downloading (…)tencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 15.1MB/s]\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing ColBERT: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ColBERT were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['roberta.embeddings.position_ids', 'linear.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[Jun 19, 18:07:53] #> Loading model checkpoint.\n",
            "[Jun 19, 18:07:53] #> Loading checkpoint ../colbertx_experiments/mMSMARCO-pt_048_dim/train.py/fine_tune_025/checkpoints/colbert-20000.dnn ..\n",
            "[Jun 19, 18:08:50] #> checkpoint['epoch'] = 0\n",
            "[Jun 19, 18:08:50] #> checkpoint['batch'] = 20000\n",
            "{\n",
            "    \"root\": \"..\\/colbertx_experiments\\/\",\n",
            "    \"experiment\": \"mMSMARCO-pt_048_dim\",\n",
            "    \"run\": \"fine_tune_025\",\n",
            "    \"rank\": -1,\n",
            "    \"similarity\": \"l2\",\n",
            "    \"dim\": 48,\n",
            "    \"query_maxlen\": 32,\n",
            "    \"doc_maxlen\": 480,\n",
            "    \"mask_punctuation\": false,\n",
            "    \"resume\": false,\n",
            "    \"resume_optimizer\": false,\n",
            "    \"checkpoint\": \"..\\/colbertx_experiments\\/mMSMARCO-pt_048_dim\\/train.py\\/fine_tune_012\\/checkpoints\\/colbert-20000.dnn\",\n",
            "    \"lr\": 3e-6,\n",
            "    \"maxsteps\": 20000,\n",
            "    \"bsize\": 12,\n",
            "    \"accumsteps\": 1,\n",
            "    \"amp\": true,\n",
            "    \"base_model\": \"xlm-roberta-large\",\n",
            "    \"triples\": \"..\\/mMARCO_triplets_025.tsv\",\n",
            "    \"queries\": null,\n",
            "    \"collection\": null\n",
            "}\n",
            "\n",
            "\n",
            "[Jun 19, 18:30:51] [0] \t\t #> Completed batch #0 (starting at passage #0) \t\tPassages/min: 9.5k (overall),  9.5k (this encoding),  319857.6M (this saving)\n",
            "[Jun 19, 18:31:10] [0] \t\t #> Saved batch #0 to /content/clueweb22-pt_10M_sample_part_00_index/0.pt \t\t Saving Throughput = 663.7k passages per minute.\n",
            "\n",
            "[Jun 19, 18:53:12] [0] \t\t #> Completed batch #1 (starting at passage #209715) \t\tPassages/min: 9.5k (overall),  9.5k (this encoding),  303313.3M (this saving)\n",
            "[Jun 19, 18:53:32] [0] \t\t #> Saved batch #1 to /content/clueweb22-pt_10M_sample_part_00_index/1.pt \t\t Saving Throughput = 634.7k passages per minute.\n",
            "\n",
            "[Jun 19, 19:15:12] [0] \t\t #> Completed batch #2 (starting at passage #419430) \t\tPassages/min: 9.5k (overall),  9.7k (this encoding),  197664.8M (this saving)\n",
            "[Jun 19, 19:15:31] [0] \t\t #> Saved batch #2 to /content/clueweb22-pt_10M_sample_part_00_index/2.pt \t\t Saving Throughput = 658.6k passages per minute.\n",
            "\n",
            "[Jun 19, 19:37:16] [0] \t\t #> Completed batch #3 (starting at passage #629145) \t\tPassages/min: 9.5k (overall),  9.6k (this encoding),  237732.0M (this saving)\n",
            "[Jun 19, 19:37:36] [0] \t\t #> Saved batch #3 to /content/clueweb22-pt_10M_sample_part_00_index/3.pt \t\t Saving Throughput = 639.0k passages per minute.\n",
            "\n",
            "[Jun 19, 19:59:21] [0] \t\t #> Completed batch #4 (starting at passage #838860) \t\tPassages/min: 9.5k (overall),  9.6k (this encoding),  306840.2M (this saving)\n",
            "[Jun 19, 19:59:43] [0] \t\t #> Saved batch #4 to /content/clueweb22-pt_10M_sample_part_00_index/4.pt \t\t Saving Throughput = 590.3k passages per minute.\n",
            "\n",
            "[Jun 19, 20:21:59] [0] \t\t #> Completed batch #5 (starting at passage #1048575) \t\tPassages/min: 9.5k (overall),  9.4k (this encoding),  301580.0M (this saving)\n",
            "[Jun 19, 20:22:22] [0] \t\t #> Saved batch #5 to /content/clueweb22-pt_10M_sample_part_00_index/5.pt \t\t Saving Throughput = 573.2k passages per minute.\n",
            "\n",
            "[Jun 19, 20:44:29] [0] \t\t #> Completed batch #6 (starting at passage #1258290) \t\tPassages/min: 9.4k (overall),  9.5k (this encoding),  172472.2M (this saving)\n",
            "[Jun 19, 20:44:50] [0] \t\t #> Saved batch #6 to /content/clueweb22-pt_10M_sample_part_00_index/6.pt \t\t Saving Throughput = 598.1k passages per minute.\n",
            "\n",
            "[Jun 19, 21:06:59] [0] \t\t #> Completed batch #7 (starting at passage #1468005) \t\tPassages/min: 9.4k (overall),  9.5k (this encoding),  319857.6M (this saving)\n",
            "[Jun 19, 21:07:21] [0] \t\t #> Saved batch #7 to /content/clueweb22-pt_10M_sample_part_00_index/7.pt \t\t Saving Throughput = 590.7k passages per minute.\n",
            "\n",
            "[Jun 19, 21:29:27] [0] \t\t #> Completed batch #8 (starting at passage #1677720) \t\tPassages/min: 9.4k (overall),  9.5k (this encoding),  334028.5M (this saving)\n",
            "[Jun 19, 21:29:47] [0] \t\t #> Saved batch #8 to /content/clueweb22-pt_10M_sample_part_00_index/8.pt \t\t Saving Throughput = 644.0k passages per minute.\n",
            "\n",
            "[Jun 19, 21:41:32] [0] \t\t #> Completed batch #9 (starting at passage #1887435) \t\tPassages/min: 9.4k (overall),  9.6k (this encoding),  153956.0M (this saving)\n",
            "[Jun 19, 21:41:32] [0] \t\t [NOTE] Done with local share.\n",
            "[Jun 19, 21:41:32] [0] \t\t #> Joining saver thread.\n",
            "[Jun 19, 21:41:41] [0] \t\t #> Saved batch #9 to /content/clueweb22-pt_10M_sample_part_00_index/9.pt \t\t Saving Throughput = 793.2k passages per minute.\n",
            "\n",
            "[Jun 19, 21:41:41] Saving (the following) metadata to /content/clueweb22-pt_10M_sample_part_00_index/metadata.json ..\n",
            "Namespace(root='experiments', experiment='dirty', run='2023-06-19_18.07.14', rank=-1, similarity='l2', dim=48, query_maxlen=32, doc_maxlen=480, mask_punctuation=False, checkpoint='../colbertx_experiments/mMSMARCO-pt_048_dim/train.py/fine_tune_025/checkpoints/colbert-20000.dnn', bsize=576, amp=True, collection='/content/clueweb22-pt_colbertx_00.tsv', index_root='/content', index_name='clueweb22-pt_10M_sample_part_00_index', chunksize=9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total time to create the ColBERT-X index: {}\".format(time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwhEfp7arazh",
        "outputId": "2372303f-bbd1-4f8b-83d9-56e462f3f8ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time to create the ColBERT-X index: 12896.436394691467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now, generate the FAISS index"
      ],
      "metadata": {
        "id": "ef55epFHnpta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "OgH3ddbgrgRI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m xlmr_colbert.index_faiss --index_root /content --index_name {COLBERTX_INDEX_FOLDER}"
      ],
      "metadata": {
        "id": "9JZXsWqznpxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a274aaa-1d6c-4ade-b393-a2f51fa66690"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-19 21:42:06.603027: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-06-19 21:42:06.661820: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-19 21:42:08.415455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "\n",
            "[Jun 19, 21:42:13] #> Creating directory /content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/experiments/dirty/index_faiss.py/2023-06-19_21.42.10 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[Jun 19, 21:42:17] #> Creating directory /content/drive/MyDrive/unicamp/ia368v_dd/trabalho_final_UNICAMP-IR/ColBERT-X/experiments/dirty/index_faiss.py/2023-06-19_21.42.10/logs/ \n",
            "\n",
            "\n",
            "[Jun 19, 21:42:18] {'root': 'experiments', 'experiment': 'dirty', 'run': '2023-06-19_21.42.10', 'rank': -1, 'index_root': '/content', 'index_name': 'clueweb22-pt_10M_sample_part_00_index', 'partitions': None, 'sample': None, 'slices': 1} \n",
            "\n",
            "#> num_embeddings = 580720308\n",
            "\n",
            "\n",
            "\n",
            "[Jun 19, 21:42:18] [WARNING] \t You did not specify --partitions!\n",
            "[Jun 19, 21:42:18] [WARNING] \t Default computation chooses 262144 partitions (for 580720308 embeddings)\n",
            "\n",
            "\n",
            "\n",
            "[Jun 19, 21:42:18] #> Starting..\n",
            "[Jun 19, 21:42:18] #> Processing slice #1 of 1 (range 0..10).\n",
            "[Jun 19, 21:42:18] #> Will write to /content/clueweb22-pt_10M_sample_part_00_index/ivfpq.262144.faiss.\n",
            "[Jun 19, 21:42:18] #> Loading /content/clueweb22-pt_10M_sample_part_00_index/0.sample ...\n",
            "[Jun 19, 21:42:19] #> Loading /content/clueweb22-pt_10M_sample_part_00_index/1.sample ...\n",
            "[Jun 19, 21:42:20] #> Loading /content/clueweb22-pt_10M_sample_part_00_index/2.sample ...\n",
            "[Jun 19, 21:42:22] #> Loading /content/clueweb22-pt_10M_sample_part_00_index/3.sample ...\n",
            "[Jun 19, 21:42:23] #> Loading /content/clueweb22-pt_10M_sample_part_00_index/4.sample ...\n",
            "[Jun 19, 21:42:24] #> Loading /content/clueweb22-pt_10M_sample_part_00_index/5.sample ...\n",
            "[Jun 19, 21:42:24] #> Loading /content/clueweb22-pt_10M_sample_part_00_index/6.sample ...\n",
            "[Jun 19, 21:42:25] #> Loading /content/clueweb22-pt_10M_sample_part_00_index/7.sample ...\n",
            "[Jun 19, 21:42:25] #> Loading /content/clueweb22-pt_10M_sample_part_00_index/8.sample ...\n",
            "[Jun 19, 21:42:25] #> Loading /content/clueweb22-pt_10M_sample_part_00_index/9.sample ...\n",
            "#> Sample has shape (29036011, 48)\n",
            "[Jun 19, 21:42:26] Preparing resources for 1 GPUs.\n",
            "[Jun 19, 21:42:26] #> Training with the vectors...\n",
            "[Jun 19, 21:42:26] #> Training now (using 1 GPUs)...\n",
            "1083.9890410900116\n",
            "784.2275936603546\n",
            "0.03591799736022949\n",
            "[Jun 19, 22:13:34] Done training!\n",
            "\n",
            "[Jun 19, 22:13:35] #> Indexing the vectors...\n",
            "[Jun 19, 22:13:35] #> Loading ('/content/clueweb22-pt_10M_sample_part_00_index/0.pt',) (from queue)...\n",
            "[Jun 19, 22:14:01] #> Processing a sub_collection with shape (60681492, 48)\n",
            "[Jun 19, 22:14:01] Add data with shape (60681492, 48) (offset = 0)..\n",
            "  IndexIVFPQ size 0 -> GpuIndexIVFPQ indicesOptions=0 usePrecomputed=0 useFloat16=1 reserveVecs=33554432\n",
            "33488896/60681492 (125.471 s)   Flush indexes to CPU\n",
            "60620800/60681492 (245.544 s)   Flush indexes to CPU\n",
            "add(.) time: 254.567 s \t\t--\t\t index.ntotal = 60681492\n",
            "[Jun 19, 22:18:18] #> Loading ('/content/clueweb22-pt_10M_sample_part_00_index/1.pt',) (from queue)...\n",
            "[Jun 19, 22:18:19] #> Processing a sub_collection with shape (60952457, 48)\n",
            "[Jun 19, 22:18:19] Add data with shape (60952457, 48) (offset = 60681492)..\n",
            "33488896/60952457 (140.920 s)   Flush indexes to CPU\n",
            "60948480/60952457 (264.058 s)   Flush indexes to CPU\n",
            "add(.) time: 273.091 s \t\t--\t\t index.ntotal = 121633949\n",
            "[Jun 19, 22:22:52] #> Loading ('/content/clueweb22-pt_10M_sample_part_00_index/2.pt',) (from queue)...\n",
            "[Jun 19, 22:22:52] #> Processing a sub_collection with shape (60691411, 48)\n",
            "[Jun 19, 22:22:52] Add data with shape (60691411, 48) (offset = 121633949)..\n",
            "33488896/60691411 (140.836 s)   Flush indexes to CPU\n",
            "60686336/60691411 (262.723 s)   Flush indexes to CPU\n",
            "add(.) time: 271.694 s \t\t--\t\t index.ntotal = 182325360\n",
            "[Jun 19, 22:27:24] #> Loading ('/content/clueweb22-pt_10M_sample_part_00_index/3.pt',) (from queue)...\n",
            "[Jun 19, 22:27:25] #> Processing a sub_collection with shape (60804091, 48)\n",
            "[Jun 19, 22:27:25] Add data with shape (60804091, 48) (offset = 182325360)..\n",
            "33488896/60804091 (141.534 s)   Flush indexes to CPU\n",
            "60751872/60804091 (264.553 s)   Flush indexes to CPU\n",
            "add(.) time: 273.549 s \t\t--\t\t index.ntotal = 243129451\n",
            "[Jun 19, 22:31:58] #> Loading ('/content/clueweb22-pt_10M_sample_part_00_index/4.pt',) (from queue)...\n",
            "[Jun 19, 22:31:59] #> Processing a sub_collection with shape (61086503, 48)\n",
            "[Jun 19, 22:31:59] Add data with shape (61086503, 48) (offset = 243129451)..\n",
            "33488896/61086503 (143.118 s)   Flush indexes to CPU\n",
            "61079552/61086503 (267.466 s)   Flush indexes to CPU\n",
            "add(.) time: 276.787 s \t\t--\t\t index.ntotal = 304215954\n",
            "[Jun 19, 22:36:36] #> Loading ('/content/clueweb22-pt_10M_sample_part_00_index/5.pt',) (from queue)...\n",
            "[Jun 19, 22:36:36] #> Processing a sub_collection with shape (60946625, 48)\n",
            "[Jun 19, 22:36:36] Add data with shape (60946625, 48) (offset = 304215954)..\n",
            "33488896/60946625 (142.214 s)   Flush indexes to CPU\n",
            "60882944/60946625 (269.960 s)   Flush indexes to CPU\n",
            "add(.) time: 280.222 s \t\t--\t\t index.ntotal = 365162579\n",
            "[Jun 19, 22:41:17] #> Loading ('/content/clueweb22-pt_10M_sample_part_00_index/6.pt',) (from queue)...\n",
            "[Jun 19, 22:41:17] #> Processing a sub_collection with shape (60986014, 48)\n",
            "[Jun 19, 22:41:17] Add data with shape (60986014, 48) (offset = 365162579)..\n",
            "33488896/60986014 (143.862 s)   Flush indexes to CPU\n",
            "60948480/60986014 (270.144 s)   Flush indexes to CPU\n",
            "add(.) time: 279.597 s \t\t--\t\t index.ntotal = 426148593\n",
            "[Jun 19, 22:45:57] #> Loading ('/content/clueweb22-pt_10M_sample_part_00_index/7.pt',) (from queue)...\n",
            "[Jun 19, 22:45:57] #> Processing a sub_collection with shape (60964381, 48)\n",
            "[Jun 19, 22:45:57] Add data with shape (60964381, 48) (offset = 426148593)..\n",
            "33488896/60964381 (142.501 s)   Flush indexes to CPU\n",
            "60948480/60964381 (268.673 s)   Flush indexes to CPU\n",
            "add(.) time: 278.199 s \t\t--\t\t index.ntotal = 487112974\n",
            "[Jun 19, 22:50:36] #> Loading ('/content/clueweb22-pt_10M_sample_part_00_index/8.pt',) (from queue)...\n",
            "[Jun 19, 22:50:36] #> Processing a sub_collection with shape (60862551, 48)\n",
            "[Jun 19, 22:50:36] Add data with shape (60862551, 48) (offset = 487112974)..\n",
            "33488896/60862551 (145.247 s)   Flush indexes to CPU\n",
            "60817408/60862551 (273.366 s)   Flush indexes to CPU\n",
            "add(.) time: 283.393 s \t\t--\t\t index.ntotal = 547975525\n",
            "[Jun 19, 22:55:20] #> Loading ('/content/clueweb22-pt_10M_sample_part_00_index/9.pt',) (from queue)...\n",
            "[Jun 19, 22:55:20] #> Processing a sub_collection with shape (32744783, 48)\n",
            "[Jun 19, 22:55:20] Add data with shape (32744783, 48) (offset = 547975525)..\n",
            "32702464/32744783 (140.353 s)   Flush indexes to CPU\n",
            "add(.) time: 150.981 s \t\t--\t\t index.ntotal = 580720308\n",
            "[Jun 19, 22:57:51] Done indexing!\n",
            "[Jun 19, 22:57:51] Writing index to /content/clueweb22-pt_10M_sample_part_00_index/ivfpq.262144.faiss ...\n",
            "[Jun 19, 22:58:37] \n",
            "\n",
            "Done! All complete (for slice #1 of 1)!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total time to create the FAISS index: {}\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "-A7QIHxBnp03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb391526-6e4b-4948-9c31-a821ba976df2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time to create the FAISS index: 4614.8285093307495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jiWrdLlOnqPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}